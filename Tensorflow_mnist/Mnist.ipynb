{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-2fb190d17fc7>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data//train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data//train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./mnist/data//t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data//t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('./mnist/data//', one_hot=True)\n",
    "#from tf.keras.dataset.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DropOut\n",
    "  - 학습 시, 전체신경망 중 일부만을 사용하는 것\n",
    "  \n",
    "    학습 단계마다 일부 뉴런을 제거하여 일부 특징이 특정 뉴런들에게만 고정되는 것을 막아 가중치의\n",
    "    균형을 잡도록 하여 과적합을 방지\n",
    "    \n",
    "    단, 학습 시에만 적용하고, 실제 예측 시에는 전체신경망을 사용해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "L2 = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "model = tf.matmul(L2, W3)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y)\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minibatch\n",
    "  - 샘플의 수가 너무 많은 경우에는 한번에 처리하기에는 하드웨어적으로 연산을 하는 속도가 느려질 수 있어\n",
    "    이에 나눠서 학습을 시키도록 하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "print(total_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg. cost =  [0.4074488  0.42175654 0.42169622 0.44475466 0.44660845 0.44285664\n",
      " 0.44632038 0.4692737  0.41593516 0.42370862 0.4145917  0.44688985\n",
      " 0.40686646 0.38492483 0.44857883 0.45105627 0.40637353 0.42175835\n",
      " 0.4634751  0.45373777 0.40945667 0.39595422 0.37703186 0.41754574\n",
      " 0.47303694 0.4041922  0.37237433 0.48258817 0.46330094 0.3539503\n",
      " 0.3828837  0.3485004  0.40435135 0.41780356 0.47710344 0.405792\n",
      " 0.45877087 0.42688128 0.41619712 0.36885336 0.39581224 0.43085635\n",
      " 0.39963567 0.41784126 0.38124743 0.4179767  0.39151105 0.47109565\n",
      " 0.42314434 0.47920245 0.3977521  0.4574014  0.4650848  0.46674627\n",
      " 0.4226881  0.41845044 0.45594797 0.40524623 0.4595337  0.46135002\n",
      " 0.4161033  0.37255654 0.45784503 0.37414968 0.41079465 0.47900373\n",
      " 0.42785227 0.49283636 0.47576126 0.3773641  0.5192967  0.41181338\n",
      " 0.39950234 0.38409272 0.42342436 0.40777132 0.36784625 0.39655036\n",
      " 0.38085464 0.41810837 0.4073453  0.4151066  0.42176098 0.41112894\n",
      " 0.3719669  0.4100604  0.5188356  0.44358122 0.55923486 0.43619126\n",
      " 0.46637505 0.403733   0.41457593 0.43563825 0.42657068 0.3985518\n",
      " 0.45779094 0.425541   0.43652445 0.3952818 ]\n",
      "Epoch: 0002 Avg. cost =  [0.14899799 0.15071152 0.14226438 0.21953097 0.13540502 0.17207359\n",
      " 0.16285443 0.15782999 0.24337862 0.17783667 0.1942889  0.16015737\n",
      " 0.15386465 0.2001575  0.12384292 0.12790449 0.1802444  0.19323689\n",
      " 0.16348054 0.14636143 0.17111976 0.12720746 0.15551592 0.16742055\n",
      " 0.18701613 0.1373706  0.16842882 0.18068954 0.15143047 0.16642398\n",
      " 0.18350662 0.20977435 0.16744828 0.15388797 0.13822864 0.1666588\n",
      " 0.18787295 0.15003392 0.18032564 0.16825776 0.15488595 0.1716739\n",
      " 0.16612679 0.1803398  0.12030599 0.15692784 0.13289379 0.17076413\n",
      " 0.14943779 0.16692589 0.12096508 0.13166511 0.16242525 0.1385179\n",
      " 0.15311214 0.20392895 0.15989357 0.159938   0.19229016 0.16232283\n",
      " 0.17729145 0.15770113 0.17059456 0.16577502 0.13900895 0.17362191\n",
      " 0.13161418 0.1673453  0.18430972 0.19482045 0.18108875 0.14248806\n",
      " 0.20911245 0.17616804 0.15759139 0.11414804 0.17457321 0.15990509\n",
      " 0.12738974 0.22465432 0.146449   0.14900659 0.1755638  0.21026045\n",
      " 0.15042706 0.16269174 0.157639   0.19335884 0.17487182 0.19343992\n",
      " 0.10721432 0.18139346 0.14277793 0.1697071  0.13222575 0.17186686\n",
      " 0.17710385 0.12696402 0.1839542  0.132481  ]\n",
      "Epoch: 0003 Avg. cost =  [0.10640025 0.11107619 0.09955682 0.1313449  0.10587785 0.11510625\n",
      " 0.10087671 0.1254662  0.10442249 0.14632209 0.10597663 0.10656773\n",
      " 0.12398475 0.10328495 0.11687183 0.11410653 0.11544244 0.15414949\n",
      " 0.09127431 0.12997146 0.09179741 0.12932497 0.1169822  0.09839829\n",
      " 0.11504477 0.09974065 0.09747931 0.0685377  0.11874344 0.11124064\n",
      " 0.11403607 0.11048664 0.09290531 0.12647422 0.11865902 0.14499938\n",
      " 0.10952951 0.08964261 0.09996972 0.11556158 0.09067636 0.11681982\n",
      " 0.1236376  0.10956408 0.08458094 0.13693067 0.12651914 0.16882417\n",
      " 0.11173414 0.08848984 0.10574099 0.12702872 0.12143639 0.13656853\n",
      " 0.11861754 0.09249078 0.10427803 0.10196846 0.10508439 0.13096458\n",
      " 0.11054016 0.07658419 0.10753616 0.1193783  0.09271795 0.08909558\n",
      " 0.10979255 0.12934424 0.1373388  0.12513372 0.10569222 0.11452811\n",
      " 0.16844392 0.13180245 0.14219074 0.10202645 0.1355634  0.10986844\n",
      " 0.0675895  0.17723306 0.13214195 0.09128696 0.13260075 0.113595\n",
      " 0.11553176 0.12416984 0.16913009 0.1044951  0.09215335 0.1171636\n",
      " 0.11596722 0.10579249 0.1027686  0.12547807 0.12578188 0.10956796\n",
      " 0.11898461 0.12008438 0.12935854 0.10364437]\n",
      "Epoch: 0004 Avg. cost =  [0.10420988 0.07517903 0.09051821 0.06954993 0.09165819 0.08944327\n",
      " 0.07061092 0.10308269 0.10825211 0.12292524 0.0937767  0.11123797\n",
      " 0.07501312 0.07787978 0.06826884 0.09175984 0.09773976 0.07565119\n",
      " 0.07033029 0.08205236 0.07045806 0.07592203 0.08132064 0.09475703\n",
      " 0.08817387 0.07076759 0.06246613 0.09876747 0.10265413 0.08012168\n",
      " 0.07198543 0.07301252 0.10631245 0.09752719 0.07822629 0.09912249\n",
      " 0.09608744 0.10777387 0.07894943 0.09100778 0.15057676 0.08530646\n",
      " 0.0787613  0.08036163 0.08208795 0.12585834 0.09633749 0.0870875\n",
      " 0.13554962 0.1036277  0.12761939 0.07258242 0.09052388 0.07177038\n",
      " 0.15594785 0.07129743 0.1032481  0.06950304 0.07875428 0.08636992\n",
      " 0.09850086 0.09796093 0.06963301 0.0925753  0.0817388  0.09398665\n",
      " 0.08614236 0.08855285 0.05396967 0.10483538 0.09728226 0.08510838\n",
      " 0.07422616 0.0720338  0.11181335 0.10382935 0.08530018 0.07196946\n",
      " 0.0840649  0.10041726 0.072819   0.08322892 0.10086673 0.08698439\n",
      " 0.10043772 0.08128459 0.06717665 0.07140476 0.09580592 0.10802063\n",
      " 0.07934342 0.08249933 0.05308764 0.08084618 0.09741659 0.09467294\n",
      " 0.07600324 0.11362325 0.08210286 0.06968609]\n",
      "Epoch: 0005 Avg. cost =  [0.07075869 0.06535884 0.07573862 0.07344502 0.0818362  0.0690503\n",
      " 0.07553469 0.06822237 0.08889745 0.03803888 0.07598807 0.04230474\n",
      " 0.0932577  0.04908209 0.06738608 0.08715498 0.05913005 0.0573192\n",
      " 0.10030627 0.07555832 0.09741855 0.04722272 0.05898034 0.08223977\n",
      " 0.07439481 0.07921452 0.08196264 0.10328145 0.09491058 0.08204198\n",
      " 0.07330222 0.05989817 0.08364929 0.10396097 0.08745194 0.04859087\n",
      " 0.04453897 0.0893255  0.06888041 0.07544526 0.05578161 0.05426315\n",
      " 0.05964983 0.06514744 0.08219025 0.09974267 0.05989562 0.04573874\n",
      " 0.05164601 0.07742999 0.05112228 0.0672438  0.07544518 0.06871122\n",
      " 0.07969542 0.06706331 0.08517657 0.07118752 0.07153493 0.06093434\n",
      " 0.0831451  0.05743982 0.08707146 0.05780028 0.07618558 0.10736192\n",
      " 0.08613996 0.04860975 0.07597794 0.08110575 0.05868466 0.10134024\n",
      " 0.052782   0.08678386 0.07894927 0.08615539 0.09814369 0.08950578\n",
      " 0.05087087 0.0592074  0.06470864 0.07370564 0.06320336 0.07580303\n",
      " 0.0931977  0.06162716 0.06290679 0.04961776 0.06381804 0.06775695\n",
      " 0.06937531 0.04527879 0.09754511 0.0652501  0.06469011 0.0603502\n",
      " 0.04961919 0.08026886 0.06448982 0.07970538]\n",
      "Epoch: 0006 Avg. cost =  [0.0549479  0.07518755 0.07358184 0.05841691 0.05759042 0.07921936\n",
      " 0.06503326 0.05133975 0.06025977 0.05461718 0.06732105 0.04491474\n",
      " 0.04196111 0.06318067 0.04169749 0.05426764 0.05676896 0.06080954\n",
      " 0.08411636 0.05325171 0.09491173 0.07610667 0.04270521 0.0527826\n",
      " 0.08236227 0.06020815 0.08153912 0.06101924 0.06614892 0.05246301\n",
      " 0.07154805 0.06935184 0.05403441 0.050808   0.04597632 0.06383706\n",
      " 0.04493641 0.10212144 0.07582459 0.05013921 0.05402189 0.02204375\n",
      " 0.06062491 0.09770758 0.07016864 0.07526374 0.06713536 0.05149471\n",
      " 0.09205336 0.08520262 0.03458758 0.06854689 0.06016432 0.04697226\n",
      " 0.06172447 0.06458731 0.04305403 0.04158549 0.07540786 0.04125153\n",
      " 0.06396089 0.05496186 0.06832931 0.0487621  0.06939442 0.05412826\n",
      " 0.05657902 0.0587592  0.05827842 0.07635239 0.05552475 0.07963714\n",
      " 0.05479653 0.0560377  0.07499576 0.04808254 0.05514313 0.06897049\n",
      " 0.05696561 0.0690848  0.06102617 0.0662908  0.05388974 0.04871683\n",
      " 0.03564117 0.0830581  0.08324217 0.04301441 0.05334264 0.0978298\n",
      " 0.06545199 0.05703706 0.0615937  0.07482065 0.07000102 0.02834663\n",
      " 0.07544181 0.05707552 0.04428451 0.0578949 ]\n",
      "Epoch: 0007 Avg. cost =  [0.0743064  0.0323017  0.04017771 0.05818328 0.03795673 0.06448277\n",
      " 0.05439766 0.04776514 0.0570191  0.07776204 0.0420842  0.0482341\n",
      " 0.04029395 0.04494284 0.07526881 0.04635612 0.03898144 0.05178431\n",
      " 0.05941411 0.06476128 0.05571053 0.03968853 0.05156659 0.0505803\n",
      " 0.06557396 0.02725302 0.0492217  0.06701558 0.06437409 0.04438788\n",
      " 0.05701765 0.0543459  0.04983258 0.0533464  0.06370492 0.04247694\n",
      " 0.06651701 0.07724175 0.04390125 0.04229925 0.05583413 0.03683911\n",
      " 0.04258494 0.05123714 0.05094493 0.03882688 0.03643162 0.044786\n",
      " 0.05970348 0.06629949 0.08601113 0.04991361 0.02795927 0.05716467\n",
      " 0.06579775 0.0373984  0.05423975 0.03985311 0.04899978 0.0476718\n",
      " 0.06615493 0.0670884  0.05481537 0.07106656 0.0544667  0.05347356\n",
      " 0.03066607 0.04232003 0.05773007 0.07140349 0.0520336  0.05158816\n",
      " 0.03903866 0.06301193 0.0559155  0.05452728 0.0484744  0.06423207\n",
      " 0.074881   0.0664345  0.03894337 0.06133096 0.04898415 0.05836692\n",
      " 0.04439304 0.06034419 0.02892242 0.04903832 0.05713406 0.07004723\n",
      " 0.05265529 0.04297959 0.06859314 0.06090385 0.04820564 0.04784703\n",
      " 0.03806243 0.05973706 0.04748897 0.06882612]\n",
      "Epoch: 0008 Avg. cost =  [0.05188537 0.03797214 0.0381212  0.05018085 0.03308541 0.04185975\n",
      " 0.04856028 0.06367356 0.04467236 0.04419854 0.0726715  0.0685922\n",
      " 0.03931534 0.04243281 0.05451567 0.03406142 0.0432786  0.0413335\n",
      " 0.03907255 0.04126382 0.06799109 0.04074238 0.05761251 0.05238856\n",
      " 0.07448524 0.06410907 0.06139881 0.03857826 0.05493969 0.0568917\n",
      " 0.02159217 0.07195707 0.03282269 0.05096329 0.05233971 0.05440265\n",
      " 0.06059627 0.06239291 0.0510159  0.08953653 0.02544711 0.0317825\n",
      " 0.03072767 0.08249145 0.08427994 0.03790896 0.0513616  0.04650751\n",
      " 0.05723654 0.03382261 0.02288739 0.03352001 0.06513524 0.02579057\n",
      " 0.04154448 0.03785831 0.04999662 0.0603483  0.04972844 0.05679363\n",
      " 0.05943751 0.06480885 0.04519584 0.03592068 0.03272697 0.05909866\n",
      " 0.06128554 0.0527011  0.03160908 0.05113361 0.06325607 0.03563171\n",
      " 0.04241242 0.03321305 0.05937799 0.05262031 0.02209988 0.03335846\n",
      " 0.06655195 0.0620461  0.02789135 0.04661616 0.06886246 0.02989463\n",
      " 0.05020484 0.0374107  0.04365506 0.06395938 0.0419846  0.03587711\n",
      " 0.06367595 0.06043583 0.04027384 0.0376064  0.05121625 0.06929825\n",
      " 0.03371337 0.05189457 0.03161964 0.05573334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0009 Avg. cost =  [0.02914098 0.03144027 0.03451856 0.04536369 0.04161472 0.05560974\n",
      " 0.05034228 0.03287307 0.06175669 0.05349905 0.03105707 0.03337504\n",
      " 0.05221076 0.02901389 0.04610364 0.03801666 0.03921135 0.02737389\n",
      " 0.03356939 0.05683125 0.04959627 0.03526085 0.04660518 0.06418615\n",
      " 0.02568137 0.03565722 0.03512614 0.05383981 0.03867033 0.03804981\n",
      " 0.03803296 0.0541949  0.04988747 0.04300691 0.06095465 0.04795524\n",
      " 0.03633149 0.04361863 0.04354869 0.06171258 0.04917463 0.04288407\n",
      " 0.02248271 0.01832331 0.02483479 0.0539258  0.03742718 0.04737276\n",
      " 0.04345114 0.02251082 0.04345138 0.04039685 0.06193495 0.04406376\n",
      " 0.02853744 0.05990369 0.05699272 0.03023122 0.03668525 0.02382116\n",
      " 0.05421913 0.02107079 0.02511645 0.03026499 0.05333136 0.02724531\n",
      " 0.03240945 0.04390945 0.06124263 0.04419545 0.04847773 0.05148584\n",
      " 0.03098103 0.05037721 0.03479299 0.06282599 0.02656057 0.05423144\n",
      " 0.02075356 0.02514239 0.04220192 0.04625835 0.04809324 0.02986193\n",
      " 0.0361148  0.02950228 0.06260786 0.03306916 0.04637733 0.0419458\n",
      " 0.04034985 0.04568776 0.05994292 0.05424164 0.01961261 0.0408513\n",
      " 0.04468528 0.03216553 0.02832399 0.04760248]\n",
      "Epoch: 0010 Avg. cost =  [0.02753662 0.04829068 0.02680383 0.04805384 0.02445141 0.03591519\n",
      " 0.03322882 0.03555817 0.02398875 0.0338575  0.02363344 0.05347592\n",
      " 0.02567368 0.08430363 0.0367812  0.03197549 0.04342876 0.02168081\n",
      " 0.02218578 0.0614922  0.03766181 0.02980784 0.04216619 0.02839066\n",
      " 0.05216991 0.05721786 0.04113678 0.03069653 0.03350288 0.03222398\n",
      " 0.03048697 0.02065813 0.03003406 0.02287143 0.05251894 0.04549144\n",
      " 0.01988735 0.02373747 0.03583122 0.06431283 0.03287579 0.02707895\n",
      " 0.03584514 0.0282712  0.02309735 0.0582828  0.04356699 0.04215791\n",
      " 0.04113451 0.03078959 0.04275244 0.02944647 0.03434009 0.02690959\n",
      " 0.02608291 0.03602487 0.03072054 0.02440297 0.03725152 0.0228921\n",
      " 0.02647655 0.04805929 0.01364844 0.01885029 0.05911097 0.01755211\n",
      " 0.03484914 0.0302668  0.03065602 0.02984869 0.01678145 0.04808068\n",
      " 0.03739243 0.02748884 0.04232103 0.02526981 0.03225885 0.02845494\n",
      " 0.03058916 0.0155047  0.03256384 0.06771751 0.02044762 0.01884437\n",
      " 0.05696428 0.02414276 0.03859407 0.04850628 0.02791139 0.03412533\n",
      " 0.04536912 0.05512019 0.05003577 0.04041101 0.0347066  0.0300796\n",
      " 0.0282157  0.07269984 0.04230997 0.03637691]\n",
      "Epoch: 0011 Avg. cost =  [0.05925976 0.03435332 0.02896652 0.0169444  0.0153849  0.02763929\n",
      " 0.04728468 0.02864082 0.05567794 0.03287967 0.0555989  0.04123265\n",
      " 0.04348312 0.01578501 0.02980959 0.04602397 0.03774032 0.01289696\n",
      " 0.04752699 0.04199487 0.03449277 0.02122641 0.03119466 0.02768073\n",
      " 0.03246465 0.03550056 0.03526241 0.03368829 0.02639346 0.02897004\n",
      " 0.03568047 0.03533247 0.02100936 0.04098366 0.03466324 0.03307748\n",
      " 0.01928815 0.02467833 0.02989013 0.02209135 0.06912337 0.03292233\n",
      " 0.02796804 0.05133285 0.02256345 0.04349881 0.03898512 0.02929224\n",
      " 0.05755313 0.02743112 0.05594406 0.03836271 0.03032426 0.03646277\n",
      " 0.04135847 0.04084648 0.05528327 0.04340178 0.01602772 0.01759005\n",
      " 0.02232949 0.02910018 0.04165782 0.0431876  0.02884088 0.02813213\n",
      " 0.02070539 0.04006261 0.03319246 0.01978778 0.03829765 0.03355308\n",
      " 0.01040136 0.02367121 0.02944095 0.0413116  0.0216764  0.04101467\n",
      " 0.02411332 0.02297853 0.04776029 0.03662276 0.03798129 0.04192138\n",
      " 0.04766074 0.05028887 0.02517675 0.03865509 0.02478839 0.03177852\n",
      " 0.05773108 0.02958114 0.03274435 0.05382322 0.01480451 0.0307495\n",
      " 0.03816199 0.03450963 0.05210212 0.04105257]\n",
      "Epoch: 0012 Avg. cost =  [0.02627125 0.01898164 0.03544595 0.0320524  0.03008255 0.03182925\n",
      " 0.05572065 0.03228032 0.02336048 0.03297677 0.02455018 0.01769411\n",
      " 0.02057121 0.03638646 0.02006972 0.03415547 0.02265796 0.02919175\n",
      " 0.01897416 0.04095763 0.01214038 0.02595598 0.01649872 0.02704107\n",
      " 0.02400612 0.0405237  0.0273757  0.04502662 0.02180013 0.03169093\n",
      " 0.0246982  0.02612977 0.04918264 0.03753081 0.03391346 0.02403407\n",
      " 0.04014208 0.05225694 0.0219753  0.02703995 0.03827965 0.03369184\n",
      " 0.04709128 0.04028623 0.0154255  0.03048927 0.03720273 0.02042997\n",
      " 0.0360104  0.02912228 0.03325678 0.0240504  0.02367303 0.0582863\n",
      " 0.03889107 0.02008987 0.03638878 0.01747572 0.03479318 0.0178141\n",
      " 0.02565346 0.01452253 0.0338348  0.03653624 0.01712949 0.01290524\n",
      " 0.03400782 0.04110562 0.04051584 0.03153793 0.04425687 0.02485202\n",
      " 0.04596397 0.03315193 0.03383527 0.02151561 0.04088458 0.02416074\n",
      " 0.01821439 0.04133693 0.02490761 0.01546328 0.02203835 0.02235375\n",
      " 0.02153326 0.03065262 0.02995182 0.03088593 0.03149754 0.0311201\n",
      " 0.04011135 0.03776091 0.03136169 0.03571776 0.02090674 0.02351198\n",
      " 0.0213772  0.02845333 0.03647991 0.0207122 ]\n",
      "Epoch: 0013 Avg. cost =  [0.03823952 0.0302091  0.02679011 0.03124912 0.01910097 0.01647971\n",
      " 0.0172352  0.04466866 0.01951577 0.03512606 0.02081741 0.0340891\n",
      " 0.02822006 0.03055172 0.05395586 0.03030436 0.0259202  0.04210631\n",
      " 0.02385309 0.04412708 0.02191837 0.0298611  0.03459706 0.03782597\n",
      " 0.02798459 0.03779076 0.01978386 0.03512782 0.02364096 0.03420317\n",
      " 0.05241701 0.03014736 0.03746874 0.02253896 0.02868904 0.05301447\n",
      " 0.04845538 0.02060402 0.02368589 0.01835    0.02268707 0.02578704\n",
      " 0.02553797 0.04616991 0.01934617 0.02231463 0.02784437 0.03741036\n",
      " 0.03041909 0.0289482  0.02915717 0.03225054 0.01570351 0.01458368\n",
      " 0.01881216 0.0319845  0.01935914 0.03698972 0.03587069 0.03967062\n",
      " 0.03855368 0.02824332 0.0456965  0.03229224 0.03908433 0.04083654\n",
      " 0.03043977 0.0180195  0.04157842 0.02985506 0.03271675 0.02303524\n",
      " 0.05074043 0.02518306 0.02673504 0.0314518  0.04721259 0.01432203\n",
      " 0.02539513 0.04387318 0.02875385 0.02478064 0.02234785 0.03155504\n",
      " 0.02771299 0.02337248 0.02879874 0.03554523 0.04045032 0.01656429\n",
      " 0.02481774 0.01878653 0.01889256 0.01896394 0.02675188 0.05757276\n",
      " 0.02517094 0.02345693 0.02081306 0.03223156]\n",
      "Epoch: 0014 Avg. cost =  [0.01151866 0.02591397 0.03095106 0.04027807 0.02678451 0.01985064\n",
      " 0.01429504 0.02325524 0.0285796  0.03112175 0.01079087 0.04121866\n",
      " 0.02409878 0.03347509 0.03845189 0.03053284 0.01061887 0.01913357\n",
      " 0.02309395 0.01410065 0.02740357 0.01704775 0.03563995 0.04333542\n",
      " 0.02351843 0.00886384 0.04206256 0.0211715  0.02200948 0.02899624\n",
      " 0.01815943 0.03398827 0.03068282 0.02248233 0.0434457  0.01720232\n",
      " 0.01688166 0.04762042 0.0417045  0.01828112 0.03821044 0.0324308\n",
      " 0.03139952 0.03365924 0.01536293 0.03641469 0.02958588 0.03806373\n",
      " 0.0285335  0.0105684  0.02570169 0.01399043 0.0267682  0.03729576\n",
      " 0.02126023 0.02151068 0.03190763 0.03669835 0.03259704 0.03102717\n",
      " 0.0220748  0.04279806 0.02248705 0.03833453 0.0139193  0.01418129\n",
      " 0.04740223 0.01842489 0.02903458 0.0193612  0.01753485 0.0501637\n",
      " 0.03249102 0.03092419 0.02139287 0.01211777 0.05314393 0.01581314\n",
      " 0.01917487 0.02751568 0.018449   0.02067502 0.0327802  0.01135651\n",
      " 0.02644043 0.00879231 0.00829161 0.0390031  0.03796792 0.02811924\n",
      " 0.0213257  0.01978714 0.02342507 0.04582103 0.03792268 0.01869729\n",
      " 0.02529027 0.0309175  0.0399448  0.01931594]\n",
      "Epoch: 0015 Avg. cost =  [0.02892333 0.02163421 0.03337314 0.01156642 0.0176353  0.04113457\n",
      " 0.02787977 0.00709811 0.05234892 0.01508981 0.01886576 0.02100355\n",
      " 0.02790239 0.02602035 0.01614033 0.02490514 0.03290605 0.01888606\n",
      " 0.04369139 0.02652426 0.01995133 0.01774812 0.0274828  0.05025162\n",
      " 0.02185311 0.01649995 0.02493802 0.02134606 0.04973684 0.02176865\n",
      " 0.00737694 0.01834401 0.01865607 0.0202867  0.02614254 0.0261267\n",
      " 0.03216    0.02142445 0.01529635 0.02482162 0.0347869  0.00431868\n",
      " 0.03745214 0.01745658 0.01977275 0.01923665 0.02558704 0.02185598\n",
      " 0.01811624 0.01955457 0.01389141 0.03178195 0.01842031 0.01214823\n",
      " 0.02135871 0.04889045 0.0372659  0.01854532 0.01800098 0.02961491\n",
      " 0.02171764 0.02879627 0.01619794 0.03897477 0.01380756 0.04468008\n",
      " 0.02172402 0.03596186 0.02220554 0.01423074 0.01606029 0.02800246\n",
      " 0.01605964 0.04242151 0.00728264 0.04334817 0.03125639 0.0436388\n",
      " 0.02956291 0.04907108 0.02170012 0.01042014 0.0206213  0.0188747\n",
      " 0.04063092 0.02612469 0.01536303 0.02903658 0.00665101 0.01503462\n",
      " 0.03379202 0.03150795 0.03055595 0.03829297 0.01121709 0.024233\n",
      " 0.02734305 0.0091462  0.01859646 0.01970183]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "    \n",
    "        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys, keep_prob: 0.8})    \n",
    "        total_cost += cost_val\n",
    "    \n",
    "    \n",
    "    print('Epoch:', '%04d' % (epoch + 1), \n",
    "          'Avg. cost = ', \n",
    "          '{}'.format((np.array(total_cost / total_batch))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9808\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(accuracy, feed_dict={X:mnist.test.images, Y:mnist.test.labels, keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과적합을 막는 또다른 방법\n",
    " - 배치정규화 (Batch Normalization)\n",
    "   \n",
    "   과적합을 막아주면서 동시에 학습 속도도 향상시킴 \n",
    "   \n",
    "   tf.nn.batch_normalization / tf.layers.batch_normalization 으로 사용 가능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13dc0a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = sess.run(model, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1})\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for _ in range(10):\n",
    "    subplot = fig.add_subplot(2, 5, _+1)\n",
    "    subplot.set_xticks([])\n",
    "    subplot.set_yticks([])\n",
    "    subplot.set_title('%d' % np.argmax(labels[_]))\n",
    "    subplot.imshow(mnist.test.images[_].reshape((28, 28)), cmap=plt.cm.gray_r)\n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
